There might be exceptions , but in general this is the case. ” King ( 2011 , p. 720 ) also underlined the need to cooperate across scholarly fields : “ …unless we are content to let data sharing work only within disciplinary silos we need to develop solutions that operate , or at least interoperate , across scholarly fields. ” Lately , the data repository situation has been evolving considerably and there are several viable alternatives providing services to store , manage , and access open research data and cite them both at the private and public level and across scholarly fields . 
Indeed , we see the emergence of numerous general‐purpose data repositories , at scales ranging from institutional , to open globally scoped repositories such as Dataverse , FigShare , Dryad , Mendeley Data , Zenodo , DataHub , DANS , and EUDat ( Wilkinson et al. , 2016 ) . 
These infrastructures mint persistent identifiers ( DOI ) , allow for versioning ( in some cases ) and accept a wide range of file formats ( Amorim , Castro , Rocha da Silva , & Ribeiro , 2016 ) . 
Moreover , in most cases they provide a ready‐to‐use text snippet ( created from manually inserted metadata ) for the data sets and links to the papers using the data sets . 
There are several other public and private services that mint and assign DOI to data sets , but do not store them and thus handle versioning “ in‐house ” ; relevant examples are the DataCite initiative 77 http : //www.datacite.org/ and the Dataverse network .88 http : //dataverse.org/ All the above‐mentioned data infrastructures worked in the direction of allowing the citation of data at fixed levels of coarseness—that is , data set , database , single file—and do not allow variable granularity data citations . 
From this , it follows that citation snippets are statically assigned to the data sets and that there are no mechanisms in place to automatically create citation snippets for data subsets defined on the fly by users . 
It emerges from the analysis we have conducted that data citation is not a by‐product of data storage and access and can not be handled just by adopting persistent identifiers or by requiring users to provide describing metadata to be used to create the citation snippets . 
Data citation requires the implementation of complex and comprehensive solutions that will have quite an impact on current data infrastructures . 
Profound changes have been taking place in the way research is done and science progresses . 
Data have become fundamental for building and interpreting new scientific results and a major player in scientific advancement . 
Experimental and observational data and scientific models are now “ born digital , ” and the progressive shift towards the data‐intensive science discovery paradigm impacts all scientific disciplines . 
Nevertheless , scientific data are still not considered first‐class players in the system of science . 
In this article we investigated the main motivations of why data citation is central for the development of science and we analyzed several studies from different scientific fields to understand their motivations and check for common elements and viewpoints . 
We have concluded that data citation is required to give credit to data creators and data curators ; it is a common belief that credit and attribution serve as an incentive to scientists for sharing more and better data , leading to the reproducibility of scientific experiments and results . 
To this end , data citation is central also for the development of executable papers that allow data to be connected with the results presented in a scientific paper ; a further extension of this view is the possibility of sustaining and validating scientific claims in a dynamic and automatic way . 
Data citation has a major impact also for easing the discovery of hidden data sources by providing new access points to them . 
Public and private institutions investing in data set creation and curation see data citation as an important means for measuring the impact of data ; this is important also for directing investments and research funding . 
In fact , the diffusion of pervasive and consistent data citation practices could lead to the definition of new impact measures and methodologies for assessing the scientific production of individuals and research institutions . 
This aspect has raised several concerned voices asking for a more profound comprehension of the norms regulating the citation of data and analyzing author citation behavior before using data citations for bibliometrics purposes . 
Despite its relevance and the attention dedicated to the topic , data citation poses a number of questions that have only been partially addressed by the information and computer science communities : ( Identification problem ) What data can be cited ? 
How do we define a data citable unit ? 
How do we identify a single resource , a subset of resources , and an aggregation of resources ? 
( Completeness problem ) When data are extracted from a large , complex , evolving database , how do we create an appropriate and informative citation for it ? 
How do we guarantee the consistency of citation texts ? 
( Fixity problem ) How do we guarantee that cited data will be accessible in their cited form ? 
We analyzed these questions in detail and provided an overview of the existing approaches to address these issues . 
We have seen that significant effort has been made to pursue the identification of data , mostly relying on PIDs . 
Other approaches use queries as proxies for identifying data , but general agreement about what is the best solution for this issue has not yet been reached . 
The completeness problem is even more open for discussion , since most solutions still rely on different forms of manual ( or computer‐aided ) creation of citation snippets , thus often leading to incomplete and inconsistent citations . 
Automatic methods are required to improve consistency and ease the citation process ; the existing automatic methods are defined for specific data models or query types and need more study and work to be generalized in order to be used for any kind of scientific data sets and general queries . 
Guaranteeing the persistency of both the cited data and citations is a fundamental task any citation system has to accomplish ; up until now , few solutions provided a fully‐fledged solution able to deal with fixity , and more research on versioning systems and time queries is required to deal efficiently with this issue . 
There are other issues connected with data citation to which not enough attention has been dedicated in the past and that could open up new research directions in the field . 
One of these is citation identity or the ability to discriminate between two citations referring to different data or different versions of the same data and between two different citations referring to the same data . 
Another challenge is citation containment or the possibility to determine if a citation refers to a superset or a subset of the data cited by another citation . 
We have also seen that only initial efforts have been conducted in the direction of defining a theory of data citing and that the understanding of the motivations for citing data and why data are cited is a challenge of fundamental importance for the definition of reliable data citation metrics and data citation indexes . 
Furthermore , easy‐to‐use citation tools have to be developed both from the data creators/curators/administrators and final users′ viewpoint . 
The former requires tools for specifying what data can be cited ( e.g. , which are the citable units ) and how data have to be cited ( e.g. , for defining rules , views , training sets , etc. ) . 
The latter require tools for actually citing the data and using the produced citations in their work . 
To this end , we may need to develop tools able to create citation for data selected through a graphical user interface and not necessarily through well‐formed and formal queries . 
