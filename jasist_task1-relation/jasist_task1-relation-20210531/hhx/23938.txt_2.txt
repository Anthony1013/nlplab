Competence depicts a learned behavior subject to external elements . 
For instance , a person can increase competence by acquiring a set of skills through training , or may fail because of situational factors outside one 's control . 
On the other hand , integrity is internal , or dispositional . 
High integrity refers to a person behaving ethically , or choosing not to harm others even when the opportunity presents itself . 
Ho and Benbasat ( 2014 ) found early evidence of stronger correlations between perceived trustworthiness and an actor 's actual betrayal activities when anomalous behavior is attributed to internal causes and more closely associated with integrity as an internal attribute—rather than competence or benevolence . 
Ho et al . 
( 2017 ) empirically tested that when an actor 's ethical dilemma is manifested in an act of deception , such integrity‐based trust violation can be unconsciously attributed by group members , and reflected in cognitive and affective group communication . 
In the context of insider threats , we exclude competence‐based and benevolence‐based trust as indicators for insider threat because an individual may be deemed incompetent and make unintentional , negligent errors , but can still be considered trustworthy . 
On the other hand , an individual who is deemed very competent could in fact behave unethically . 
Moreover , we propose that a person 's benevolence is not a strong indicator for signaling insider threat because an individual with betrayal intent could still be “ benevolent ” to friends , coworkers or subordinates . 
As such , we argue that the single factor of perceived integrity ( i.e. , integrity‐based trust ) as a measure of perceived trustworthiness would be a more effective indicator in the context of insider threats . 
We postulate that perceived integrity‐based trust correlates strongly with indicators of betrayal ( i.e. , actual trustworthiness ) , providing direct implications of insider threat against an organization ; that is , benevolence or competence does not involve intentional betrayal and is not a strong indicator of a trust violation . 
Someone who is perceived to have downward shifts in their trustworthiness , ethically speaking , may have already violated trust and engaged in betrayal activities . 
Thus , we postulate that : Proposition 2 ( P2 ) : Benevolence , as a measure of trustworthiness , is not a strong indicator of an actor 's violation of trust .Proposition 3 ( P3 ) : Competence , as a measure of trustworthiness , is not a strong indicator of an actor 's violation of trust .Proposition 4 ( P4 ) : When a focal actor 's perceived trustworthiness , in terms of integrity , is reduced , this may indicate an elevated tendency to betray the organization . 
Proposition 2 ( P2 ) : Benevolence , as a measure of trustworthiness , is not a strong indicator of an actor 's violation of trust . 
Proposition 3 ( P3 ) : Competence , as a measure of trustworthiness , is not a strong indicator of an actor 's violation of trust . 
Proposition 4 ( P4 ) : When a focal actor 's perceived trustworthiness , in terms of integrity , is reduced , this may indicate an elevated tendency to betray the organization . 
Attribution refers to an act of ascribing a result to a cause . 
Attribution theory describes a process of people attributing ( or assigning ) causes of behaviors based on observed behavior ( Heider , 1944 ) . 
These attributions differ depending on different contexts , interpretations , and the actor being studied ( Weiner , 1985 ) . 
The attribution of observed behavior can also be influenced by observers ’ judgment of whether the observed acted intentionally ( internal or dispositional causality ) or unintentionally ( external or situational causality ; Kelley , 1973 ) . 
To continue the previous analogy , regardless of a trustee 's ( i.e. , the focal actor 's ) actual motivation to betray , attribution theory argues that others observe the trustee 's behavior over time , making inferences about causes behind changes in behavior that may signify something abnormal ( Kelley , 1973 ) . 
Ho and Benbasat ( 2014 ) extended attribution theory , seeking to answer the specific question of “ how the attribution mechanism works to signal a violation of trust based on the communicative language of social actors in a virtual organization , ” and investigated how social actors ’ trustworthiness can be attributed collectively by group members based on “ language as symbolic action. ” They noted that “ in online communications , people must rely on fairly simple rudimentary evidence ( e.g. , words and actions ) to decide whether to trust another party ” ( Ho & Benbasat , 2014 , p. 1 ) . 
Consistent with earlier attribution theory , Ho and Benbasat ( 2014 ) found support for the argument that coworkers often serve as “ smart sensors , ” who can make intelligent inference and dynamic trustworthiness attributions based on the interplay of words and actions . 
Schwarz ( 2015 ) also described such subjective experiences , or meta‐level thoughts—that support inference and judgment in the reasoning process—as metacognition . 
In other words , based on simple rudimentary evidence ( i.e. , words and action ) , members of a group can decide whether their impression is “ likely to be accurate , ” or whether the impression is “ consistent ” with their baseline knowledge about a focal individual . 
Humans can make these meta‐level judgments regardless of whether others share the same impression , or whether the information on which their judgment “ came from a reliable source ” ( p. 204 ) . 
We thus postulate that : Proposition 5 ( P5 ) : Humans as “ smart sensors ” can understand and interpret subtle communication signals associated with reduced trustworthiness . 
Proposition 5 ( P5 ) : Humans as “ smart sensors ” can understand and interpret subtle communication signals associated with reduced trustworthiness . 
Moreover , a baseline expectation of normal behavior is a basic prerequisite for group 's observation in close relationships . 
Only through a close relationship in a group with a focal actor can observers develop some baseline expectation and measurement against which to compare anomalous behavior ( Rempel , Holmes , & Zanba , 1985 ) . 
When an actor 's behavior changes , an actor 's close associates will perceive and assign meaning to such behavioral changes . 
Thus , we further postulate that : Proposition 6 ( P6 ) : Close relationships in work or social groups may allow for observation of subtle cues that may indicate changes in trustworthiness . 
Proposition 6 ( P6 ) : Close relationships in work or social groups may allow for observation of subtle cues that may indicate changes in trustworthiness . 
Kelley ( 1973 ) and others ( Heider , 1944 ; Ho & Benbasat , 2014 ; Martinko & Thomson , 1998 ; Weiner , 1985 ) have included three information types in their attribution models . 
These three constructs are relevant to understanding how humans attribute trustworthiness in an organizational or group context : behavioral consistency of an actor 's words and actions , distinctiveness of an actor 's behavioral cues across time , and a level of observers ’ group consensus about causes for observed behaviors . 
That is , the evaluation of whether an actor 's words are consistent with associated actions will lead to expectations of congruence between words and actions as expressed in communication artifacts becomes an important indicator of trustworthiness . 
Consistency refers to observers concluding that a person 's words and behaviors are consistent ( reliable and expected ) over repeated interactions , thus would not raise any red flags in observers ’ inference of trustworthiness . 
People will be known in general for consistent words and actions , or the lack of it , that is , inconsistency ( e.g. , not following through on a promise ) . 
These patterns of behavior set up expectations for how other 's behavior is judged . 
As noted earlier , attributions , associated with the lack of benevolence , unkindness , or incompetence because of a stream of mistakes or errors , are not good indicators of betrayal activities . 
We thus propose that the consistency of an actor 's words and actions as interpreted by observers can indicate perceived trustworthiness , and raise the following propositions regarding ( in ) consistency of words and actions , as attributed to indicate lower trustworthiness : Proposition 7 ( P7 ) : The inconsistency between an actor 's words ( communicative intent ) and actions , when attributed to lack of benevolence , is not an indicator of lower trustworthiness .Proposition 8 ( P8 ) : The inconsistency between an actor 's words ( communicative intent ) and actions , when attributed to incompetence , is not an indicator of lower trustworthiness .Proposition 9 ( P9 ) : The inconsistency between an actor 's words ( communicative intent ) and actions , when attributed to lack of integrity , can be an indicator of lower trustworthiness . 
Proposition 7 ( P7 ) : The inconsistency between an actor 's words ( communicative intent ) and actions , when attributed to lack of benevolence , is not an indicator of lower trustworthiness . 
Proposition 8 ( P8 ) : The inconsistency between an actor 's words ( communicative intent ) and actions , when attributed to incompetence , is not an indicator of lower trustworthiness . 
Proposition 9 ( P9 ) : The inconsistency between an actor 's words ( communicative intent ) and actions , when attributed to lack of integrity , can be an indicator of lower trustworthiness . 
As the perceptions of lower trustworthiness can signal insider betrayal , proposition 10 thus serves as a confirmatory proposition based on the establishment of propositions 4 and 9 , arguing that an observer 's perception of inconsistency between the focal actor 's words and action may serve as an indicator of potential trust violations . 
Proposition 10 ( P10 ) : The inconsistency between an actor 's words ( communicative intent ) and actions , when attributed to lack of integrity , may indicate that the actor has a tendency to betray . 
Proposition 10 ( P10 ) : The inconsistency between an actor 's words ( communicative intent ) and actions , when attributed to lack of integrity , may indicate that the actor has a tendency to betray . 
The basic premise of an intrusion detection system ( IDS ) is that anomalous behaviors signal some change that should be flagged for further investigation ( Debar et al. , 1999 ; Patel et al. , 2013 ) . 
Likewise , several attribution studies have also noted that if a person 's cognitive response to certain stimulus is different from her/his responses to other similar stimuli , then there is a distinctive reaction ( Martinko & Thomson , 1998 ) . 
The focus of this inference framework does not differentiate on the type of stimuli ( e.g. , money or revenge ) that might motivate insider betrayal , or the type of actor 's cognitive response to the stimuli . 
Rather , it is focused on the groups ’ ( i.e. , smart human sensors ’ ) ability to learn and to differentiate a focal actor 's distinctive behavior from regular behavior across time when a betraying stimulus is present . 
Instead of observing the betraying stimulus , we focus on signals as observed by others . 
Ho and Benbasat ( 2014 ) defined distinctiveness as the extent to which an actor is attributed to behave distinctively different to a stimulus when compared to a generalized expectation of his/her profiled behavior over time . 
We thus can refer to distinctiveness , or a distinctive behavior , as a distinguishable , notable quality of an individual being evaluated , when compared to established baseline behavior in similar situations , with a distinctive outcome during communication . 
That is , if an actor 's behavior is noticeably different from his/her usual behavior , and the changes in that behavior are attributed to external ( or , situational ) causes , the causes of that change would be viewed as being outside of his or her control , and this actor would not be held intentionally responsible for the act . 
Hence , the actor 's integrity would not be considered compromised and his or her perceived trustworthiness would not be adversely affected . 
We similarly argue that if a certain behavior is observed to be different from a focal actor 's usual behavior , and the changes to that behavior are attributed to internal causes ( i.e. , because of a focal actor 's choice or disposition ) , the actor could be held intentionally responsible for the act , hence his/her trustworthiness ( i.e. , integrity‐based trust ) would be attributed lower . 
Because of the earlier propositions that both benevolence and competence are not indicators of betrayal , we thus postulate only one proposition illustrating the relationships between the constructs of distinctiveness in actions and trustworthiness specifically referring to integrity‐based trust violation . 
Proposition 11 ( P11 ) : When an actor acts noticeably different as compared to observers ’ baseline knowledge of the actor in similar situations , and the reason for such distinctive behavior is attributed to the actor ( internal causality ) , the actor is likely attributed to have lower trustworthiness . 
By contrast , when an actor 's behavior does not deviate from observers ’ baseline knowledge of the actor in other similar situations , and if such a behavior is attributed to be outside of the actor 's control ( external causality ) , the actor is likely attributed not to have lower trustworthiness . 
Proposition 11 ( P11 ) : When an actor acts noticeably different as compared to observers ’ baseline knowledge of the actor in similar situations , and the reason for such distinctive behavior is attributed to the actor ( internal causality ) , the actor is likely attributed to have lower trustworthiness . 
By contrast , when an actor 's behavior does not deviate from observers ’ baseline knowledge of the actor in other similar situations , and if such a behavior is attributed to be outside of the actor 's control ( external causality ) , the actor is likely attributed not to have lower trustworthiness . 
Although it is unlikely that every actor in an organization would respond to a typical betrayal stimulus in the same way—with the same communicative cues , we argue that group consensus reflects a group 's metacognitive inference process ( Schwarz , 2015 ) in attributing cause of an observed behavior . 
This collective metacognitive inference process refers to people 's ability to draw inference from each other 's memory ( Smith & Schwarz , 2016 ) and collectively know “ that they know ( collectively ) something even though they can not retrieve it at the moment… people 's confidence in the accuracy of their knowledge and memories is indicative of actual accuracy ( p. 207 ) . 
” Ho and Benbasat ( 2014 ) noted this collective attribution or sense‐making results a level of group consensus , which is the extent to which group members are in agreement ( or not ) about a focal actor 's observed behavior under typical circumstances over time . 
Group consensus ( or lack of ) is a collective response that can be observed in the trustworthiness attribution of a focal actor . 
Individual observers form their own baseline knowledge about an actor based on personal social interactions ( Lewicki & Bunker , 1996 ) . 
When an actor 's words are consistent with his or her action , and no distinctive cues of unusual behavior are noted based on baseline expectations for similar situations , group members tend to reach agreement about an actor 's behaviors . 
In the next set of propositions , we observe the variation of group consensus in relation to the attributed cause of an actor 's behavior , for example , when distinctiveness in behavior occurs ( based on established patterns of the actor 's prior behavior ) , or when inconsistency is found between an actor 's words and actions . 
Either or both of these may challenge observational agreement within groups , as baseline knowledge or “ observational templates ” about a focal actor 's usual behavior may vary across multiple observers ( Shaw , 1961 ; Steiner , 1964 ; Tuckman , 1965 ) . 
Ho et al . 
's ( 2017 ) experiments found evidence in the collective ability of groups to reflect and signal a deceptive actor in computer‐mediated group communication . 
That is , groups will display more cognitive load , affective process , and use more words of negation in group communication when a deceptive actor is present . 
By comparing a deceptive actor 's words with the words used by an interacting group , Ho et al . 
( 2017 ) further identified that a deceptive actor will use more words of negation than other interacting group members in synchronous communication . 
Lack of group consensus can also be an indicator that a focal actor 's behavior has been collectively attributed to an internal ( dispositional ) causality , resulting in lower trustworthiness ( i.e. , as measured by integrity‐based trust ) , which signals a higher risk of insider threat behavior . 
Likewise , when group agreement is observed over multiple interactions , the focal actor 's behavior is more likely to have been attributed to external ( situational ) causality ( e.g. , the actor 's competence ) , which would not result in lower trustworthiness ( i.e. , as measured by integrity‐based trust ) . 
Thus , we postulate that group consensus—or lack thereof—is a collective response that can be observed to infer the cause of an actor 's distinctive behavior—being dispositional or situational—as associated with shifts in trustworthiness specifically referring to integrity . 
Proposition 12 ( P12 ) : When groups do not reach consensus about a focal actor 's distinctive behavior , and if the behavior is attributed to disposition , then the actor is likely perceived as less trustworthy . 
Proposition 12 ( P12 ) : When groups do not reach consensus about a focal actor 's distinctive behavior , and if the behavior is attributed to disposition , then the actor is likely perceived as less trustworthy . 
Moreover , lack of group consensus over multiple interactions is a phenomenon that can be observed to infer the actor 's inconsistency between words and action as associated with perceived untrustworthiness . 
Thus , we postulate that , Proposition 13 ( P13 ) : When groups do not reach consensus about a focal actor 's inconsistency between words and actions , and if the behavior is likely attributed to disposition , then the actor is likely perceived as less trustworthy . 
Proposition 13 ( P13 ) : When groups do not reach consensus about a focal actor 's inconsistency between words and actions , and if the behavior is likely attributed to disposition , then the actor is likely perceived as less trustworthy . 
Group sensitivity affects a group 's collective ability to sense and react to anomalous behavioral cues . 
Although a group 's general consensus on cause ( i.e. , dispositional vs. situational ) based on observed behavior may be measurable , group dynamics can be quite unique and any group may be more or less sensitive to behavioral consistency or distinctive behaviors ( Shaw , 1961 ; Steiner , 1964 ) . 
Group sensitivity also represents the group 's degree of general awareness toward the focal actor 's communicative cues , for example , consistency between words and actions and also any distinctive behavioral cues ( Winship & Hardy , 1999 ) . 
In the simplest terms , the degree of group sensitivity is bidirectional ( e.g. , suspiciousness vs. trustfulness ) , which could influence each member 's attribution of trustworthiness in an exchanged message . 
Different observations by individual members will vary within a group . 
If even only one team member ( an observer ) has higher sensitivity to cues from a focal actor , this observer can influence the group 's collective view by sensitizing it to cues that might have been ignored . 
Group sensitivity can be influenced by different degrees of trustfulness across individual observers , or trustors . 
Trustfulness refers to a characteristic in the trustor . 
Every trustor may have his or her own level of trustfulness , and thus different characteristics of trustors would influence group behavior , attribution as well as agreement about observations and the cause of what is observed ( Tuckman , 1965 ) . 
Trustfulness is an inherent tendency to trust , which may cause truth bias ( Street & Masip , 2015 ) . 
The illusory halo error , or halo effect can be embedded in the observer ( or , evaluator ) ( Cooper , 1981 ) . 
That is , based on different degrees of trustfulness , an observer can be biased when being asked to make judgments , suggesting that trustfulness may influence the attribution process ( Levine & McCornack , 1991 ; Tyler & Degoey , 1996 ) . 
For example , a naïve observer tends to be biased toward believing a speaker is telling the truth ( Bond & DePaulo , 2006 ; Street & Masip , 2015 ) because of heuristic processing of information ( Kahneman & Tversky , 1972 ; Street & Masip , 2015 ) . 
Every individual observer may have different degrees of trustfulness that influences his or her belief or opinion system . 
Different characteristics and trustfulness of individual observers may further influence group behavior , dynamics and agreement about observations . 
The data analyzed in Ho and Benbasat 's ( 2014 ) study illustrates that when participants are asked to make an evaluation , their different levels of trustfulness might affect the group 's overall sensitivity . 
In an organizational context , employees may be more sensitized if they have experienced insider threats . 
Similarly , employees involved in IT Security may be more aware of potential risks of insider negligence or threat , and become more sensitized to anomalous cues . 
Regardless , different degrees of observers ’ trustfulness would likely lead to individual‐based truth bias , and might influence the group 's dynamics . 
However , the results of Ho et al . 
's ( 2017 ) experiments found strong evidence that when analyzing group communication ( in contrast to using survey instruments ) , group sensitivity to anomalous communicative cues was identifiable with statistical significance . 
This implies that the impact of the halo effect was insignificant . 
Thus , we further extended the attribution studies by adding the construct of group sensitivity that measures the degree to which a group can sense and accurately interpret anomalous behavior of a focal actor depending on different contexts . 
In short , collective reactions to a focal actor 's behavioral cues can be influenced by communication structure among observers , as well as an actor 's leadership style , power structure , and power dynamics . 
As degrees of trustfulness—based on naïve or a suspicious nature—can influence how people determine the accuracy of their belief , we argue that “ sensitivity ” must be considered when evaluating a group 's collective response and metacognition ( Schwarz , 2015 ; Smith & Schwarz , 2016 ) to communication cues . 
Proposition 14 ( P14 ) : The higher a group 's sensitivity to an actor 's behavioral changes , the more likely the group will detect inconsistencies between a focal actor 's words and actions . 
Proposition 14 ( P14 ) : The higher a group 's sensitivity to an actor 's behavioral changes , the more likely the group will detect inconsistencies between a focal actor 's words and actions . 
Unfortunately , when one observer in a group has higher or lower sensitivity to behavioral cues , this can influence and reduce the likelihood of a group reaching agreement about the focal actor 's behavior , behavioral change , or its meaning , and can result in lower overall attribution of trustworthiness . 
We thus argue that even when group sensitivity is influenced by one or more group member ( s ) , the aggregated group sensitivity will be tuned to notice anomalous cues of the focal actor . 
We further postulate that group sensitivity to the focal actor 's behavioral cues is inversely related to group consensus in attributions of cause . 
Thus , Proposition 15 ( P15 ) : The higher a group 's sensitivity is to an actor 's behavioral changes , the more likely this group will exhibit difficulty in reaching agreement on observed behaviors . 
Proposition 15 ( P15 ) : The higher a group 's sensitivity is to an actor 's behavioral changes , the more likely this group will exhibit difficulty in reaching agreement on observed behaviors . 
The above propositions aim at identifying patterns of insider betrayal based on the communication cues and artifacts exchanged between group members in either online or hybrid ( face‐to‐face and online ) settings . 
These 15 propositions are formulated based on a focal actor 's perceived trustworthiness when an actor tends to betray , or has already done so . 
Our framework requires two premises in the context of integrity‐based trust violation . 
As the main dependent construct is perceived trustworthiness , as measured by integrity , this model first states that perceived trustworthiness , attributed collectively , can be indicative of actual trustworthiness ( i.e. , betrayal ) . 
This was empirically tested in Ho et al . 
( 2017 ) experiments that indicate that perceived trustworthiness—as attributed by a close work group—is indicative of actual trustworthiness . 
Ho et al . 
( 2017 ) empirically supported this main proposition with data collected between 2008 and 2015—that a focal actor 's betrayal concealed in the deceptive activities were identifiable through groups ’ collective cognitive and affective communication with statistical significance . 
Second , this model requires a panorama of the dynamics of complex interactions between observers and any actor in close relationship ( Ho & Warkentin , 2017 ) . 
The close relationships and interaction allows an opportunity for observers to assess and attribute an actor 's perceived trustworthiness with observational accuracy . 
The panoramic ( or , multifaceted ) view of the work group environment provides the research platform and premise for a more efficient approach to analyzing relationships among various constructs as proposed in the propositions and based on available communication cues and artifacts . 
This panoramic view of insider activities enables noninvasive routine monitoring , with no violation of employee privacy . 
Insider threats represent a significant organizational problem where trusted insiders betray their colleagues and violate the collective interests of organizations . 
Current insider threat research often focuses on after‐the‐fact violations of security , access controls , or standard operating procedures . 
