That is because AR ( 1 ) predicts the word to have increasing frequency in the next time window . 
From the results , AR ( 1 ) ’ s output does complement the ranking counterpart . 
The baseline methods DL , LDA , TTM , and ADP may generate keywords that are not so closely related to the events , for instance , download , ice , cream , following , and great , sam , near , ikea . 
Especially for ADP , the generated keywords on Flood are mostly irrelevant . 
The proposed ranking method could extract keywords that are not discovered by the other models , such as californians who are affected by the aftershock of Chile earthquake and inmates who escape from the prison during the earthquake , and # infloodwetrust , # floodaware , which alert the flood . 
It 's fairly hard to judge which word is better when different models suggest different keywords and all the keywords are related to the event . 
Thus , we made a comparison of the number of tweets collected by the keywords versus those that are truly related to the event , as shown in Table 4 . 
Heuristically , with an equal number of event‐related tweets , the fewer the number of tweets that are collected the better . 
This means that the keywords generated by the method are more correlated and more concentrated on the event . 
We can see that the proposed method could extract a smaller candidate data set with similar positive tweets number than baselines . 
On the other hand , not all the positive tweets collected by the methods are predicted as event‐related . 
That is , ∣TC p ∣ does not reflect the final recall of a method . 
In this article we proposed a method for collecting event‐related tweets from Twitter Stream with high precision and high recall . 
Our proposed method consists of keyword extraction and event‐related tweet identification . 
Due to the large volume of tweets , we collect candidate tweets from Twitter Stream by a keyword search . 
We evaluated keywords to be qualified queries by three properties : relevance , coverage , and evolvement . 
We ranked keywords by a ranking function that considers both relevance and coverage . 
The evolvement property was measured by the Autoregressive time series model . 
Meanwhile , a tweet containing a keyword does not mean the tweet is event‐related . 
Identifying event‐related tweets from the collected tweets by keywords becomes another crucial component . 
To reduce the human annotation effort , we grouped near‐duplicate and similar tweets into clusters , and fit them in an active learning process . 
In addition , uncertainty sampling was used as a query strategy and multiple‐instance learning was adopted as a labeling strategy . 
We conducted experiments on two real‐world events and annotated selective parts of data as ground truth for evaluation . 
Experiment results on both data sets suggest that the proposed method outperforms state‐of‐the‐art methods . 
The method achieves the goal of high recall and high precision with little human annotation effort . 
