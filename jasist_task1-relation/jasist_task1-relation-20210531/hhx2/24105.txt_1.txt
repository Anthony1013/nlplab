The organized process of capturing , organizing , analyzing , and using data has always been integral to scientific activity . 
Its use is key to the exercise of the scientific method and the generation of reliable knowledge . 
While remaining key to scientific activity , the turning of data into action , or data work , is a set of processes that can now be regarded as integral to societal activities of all kinds ( Foster , 2016 ; Foster & Clough , 2018 ; Taylor , 1986 ) . 
Due in large part to the development of a pervasive infrastructure of networks , smartphones , sensors , and other devices , new data‐driven interactions between people and organizations have emerged . 
Search is ubiquitous , the gathering , analysis , and use of data by social media companies is routine ; health providers engage in clinical data sharing for the purposes of conducting secondary research analyses and improving treatment outcomes ( Lea et al. , 2016 ; Wilbanks & Friend , 2016 ) ; governments make use of data analytics to inform the making of law enforcement decisions ( Bachner , Ginsberg , & Hill , 2017 ) ; while business organizations draw on data analytics in order to improve their internal operations and to inform the development of automated data‐driven services ( Davenport & Harris , 2017 ) . 
While the value and uses of data work are readily apparent , there is also a widespread recognition that its processes also give rise to different categories of risk . 
These include detectable risks to people and to organizations , along with less detectable societal risks . 
The risks to people principally arise from how organizations ' processing of personally identifying information may contribute to loss of privacy , via a lack of informed consent or lack of respect for client confidentiality ; for example , via reidentification related to data linking and data sharing , or via identity theft and loss of reputation due to security breaches . 
The risks to organizations arise from a lack of systematic attention to data work ; for instance , lack of organizational policy and governance , and hence a loss of value and opportunity arising from its implementation ; or from not adhering to regulatory and other external standards ; for instance , data protection law , and sector‐specific regulations that can lead to mishandling and data breaches . 
Finally , there are the more amorphous and less detectable societal risks ; for instance , bias , unfairness , and manipulation that can arise in relation to algorithmic decision making ( Dormehl , 2015 ) . 
It is clear that the utility of data as a resource and its handling by agents of all kinds , typically but not only data and other professionals , is dependent on negotiating the trade‐off between the value and risks of data work . 
The addressing of this trade‐off at the micro level of data‐handling , interaction , and use has steered attention to the macro and meso level conditions that shape and constrain data work and its processes at a micro‐level . 
These conditions include attention to the ethical questions that arise in data work , laws , policies , and other sectoral standards that inform and regulate organizations ' handling of data , the systematization of organizations ' data handling practices and their governance , along with attention to the implications for educating and training data professionals and others who handle data on a routine basis . 
The purpose of this article is to provide a synthetic review of the value , risks , and governance of data work . 
The review is organized as follows . 
An initial section on “ data ” defines the scope and use of the term as used in the review . 
This is followed by a section on “ data work , ” initially addressing its organization and subprocesses , before providing illustrative examples of its values and risks from two principal perspectives : health and business ( Taylor , 1986 ) . 
In keeping with these perspectives , primary consideration is given to contexts of data work outside of the immediate domain of science . 
We do not include attention to other pertinent types of data work ; for instance , data archiving , data curation , where issues of ethics and intellectual property will also arise . 
The section on data work is then followed by a series of sections that address macro and meso level conditions that will influence a trade‐off between the value and risks of data work at a micro‐level . 
This includes attention to ethical and legal questions ; for instance , issues of ownership and intellectual property rights , privacy and data protection law at the macro level ; issues of governance and accountability within organizations at a meso level ; plus issues relating to the education and training of data professionals and others that inform the handling of data at the micro‐level . 
While topics relevant to the value , risks and governance of data have been studied separately ( Bachner et al. , 2017 ; Lane , Stodden , Bender , & Nissenbaum , 2014 ; Martin & Shilton , 2015 ; Shilton , 2012 ) , their interdependence and interaction within the context of data work has been accorded less attention . 
From this emerges an integrative framework , and a related set of research questions , for studying and researching the challenges that arise from data work , the conditions impinging on data work , and the consequences for individuals organizations and society . 
The received assumption has been that data work consists of a largely unspecified set of processes implemented within an operational context separate from the matrix of conditions and consequences within which it can be located . 
Where attention has been given to the context of data work , this has largely been at a macro level , with less attention accorded to its conduct at the meso and micro levels . 
The education of data scientists being a case in point . 
This article responds to this situation by ( i ) systematizing data work as a set of organizing , analyzing and judging , and decision‐making processes , and ( ii ) setting data work and its processes within the context of the conditions and consequences that have already and will continue to shape the course of its future development . 
As data work further develops as an organized set of processes that are integral to societal activities of all kinds , it can be expected that micro‐level interactions around its value and risks will entail consequences that will in turn influence its conditions . 
In doing so , attention is drawn not only to data work as a form of organized work , but also to the “ work ” required to locate data work within the sociological context of its antecedent conditions and consequences . 
The term “ data ” has been used in many different senses . 
These senses include : data as a given , data as the premises on which a subsequent calculation may be made , data as the evidence input into a problem , or data as an annotation—the latter a sense akin to what is now more commonly termed metadata ( Furner , 2016 ) . 
Of the many senses of the term , “ data ” is used here in the sense of “ content…about a referent ” ( Furner , 2016 , p. 295 ) . 
In other words , data are used in an “ informational ” sense to indicate content about an entity ; for instance , person , object , action , spatial location , and so forth . 
It is a corollary of this definition that content about the entity will also vary along a range of attribute‐values . 
For the purposes of this review , this informational sense of data subsumes other ways of considering data . 
This includes the distinction between data in either numerical or nonnumerical , textual , form—a distinction that will be pertinent to an organization 's mapping of its data resources , for example , but relevant here only to the extent that such data are to be interpreted as carrying actual or potential content about a referent , as well the key distinction between small and big data ( Borgman , 2015 ) . 
While big data clearly act as a contemporary condition for data work , it is the complexities of its volume , variety , and velocity and how these impact the informational value , risks , and governance of its processing that is of most relevance in the context of data work ( Laney , 2001 ) . 
A final distinction , that between data and digital data , also merits consideration . 
While this is also a useful distinction , for observing the contemporary significance of data in its predominantly digital rather than analog form—that is , numerical or nonnumerical data that is computable and available to be processed in machine‐readable form—the reduction of data to digital 1 ’ s and 0 ’ s is again considered pertinent here only to the extent that digital data carries actual or potential informational content about a referent . 
In other words , how digital data contribute , for example , to the value , ( for instance , real‐time processing ) , risks ( for instance , algorithmic decision making ) , and governance of data‐driven services that carry content about people , location , and other attributes . 
It is also worth bearing in mind that it is in this informational sense of data where a good many of the issues surrounding the value , risks , and governance of data work lie . 
Since apart from the integrity of data work as part of the scientific method , it is how data point either directly or indirectly to a subject ( for instance , citizen , patient , consumer , user ) that leads to much of the value ( for instance , personalization ) , risks ( for instance , loss of privacy ) , and governance challenges ( for instance , accountability , data protection ) that arise . 
Finally , the informational sense of data enables a further distinction to be made between data consisting of content about a referent , and the set of processes that are subsequently applied to that content—processes potentially enabling the systematic transformation of data into information , knowledge , and action ( Taylor , 1986 ) . 
A topic to which we now turn . 
A number of frameworks have been devised for systematizing the process of capturing , organizing , analyzing , and using data . 
These include : a value chain ( Miller & Mork , 2013 ) , an analytics value chain ( Stein , 2012 ) , and a data value cycle ( OECD , 2015 ) ; while Carter and Sholler ( 2016 ) refer to “ data science work ” and “ data analysis work ” as a “ kind of work…being done ‘ on the ground ’ ” by data analysts who extract , analyze , and use data in support of organizational goals ( p. 2310 ) . 
In this review , data work is conceived of as a set of processes organized in accordance with Taylor 's ( 1986 ) value‐added approach ( see also Foster , 2016 ; Foster & Clough , 2018 ) . 
A number of reasons make Taylor 's approach an apt choice . 
First , the value‐added model begins with data , and then proceeds via information and knowledge to action ( Taylor , 1986 , p. 6 ) . 
The definition of data that Taylor provides is also intentionally general , referring to “ symbols that designate the state of an entity at some point in time. ” Therefore , this definition provides a useful anchor , one compatible not only with an informational interpretation of data , but also sufficiently flexible in order to accommodate new characteristics of data in the contemporary era . 
Second , Taylor makes a useful distinction between processes that leave the “ data ” unchanged from input to output , and processes that do not . 
For example , while an abstracting and indexing service will add value to the organization of documents via indexing processes that provide intellectual access to these documents , the underlying “ data ” will remain the same . 
In other types of “ data work , ” the set of processes applied to the data will transform that data , and the output will contain a “ substantive difference ” from what was input . 
Taylor labels these latter processes “ information analysis ” services . 
In sum , and as the distinction implies , Taylor highlights a key difference between “ data ” and the processes applied to this data . 
This distinction is maintained here , and the value‐adding “ organizing , ” “ analyzing , ” “ judgmental , ” and “ decision ” processes that can be applied to “ data ” are called data work . 
Third , in the course of drawing attention to the transforming nature of “ information analysis services , ” Taylor also makes an additional observation as to the starting point for these analyses . 
In principle , the starting‐point for analysis can be problem‐oriented ; for instance , when providing data analyses , for example , in support of the resolution of clinical problems . 
In a different setting , such as business , the starting‐point for analysis can be more discovery and data‐driven , seeking to detect patterns that are tied more to questions , rather than to the resolution of problems . 
The latter is more pertinent to automated data‐driven services . 
This distinction is also maintained here via the use of illustrative examples of data work , from a problem‐oriented health domain on the one hand , and an automated data‐driven business domain on the other . 
Fourth , Taylor 's value‐added approach also draws attention to the key process of decision making—a key outcome of data work , irrespective of whether information analyses are used to inform processes of either human or automated decision making . 
As a way of specifying and organizing data work , and in keeping with Taylor 's value‐added approach , we follow his broad set of “ organizing , ” “ analyzing , ” “ judgmental , ” and “ decision ” processes . 
We maintain this set of distinct subprocesses in general only , and do not go into detail as to the values that can be added in data work . 
This is a question for future research . 
In a health setting , the process of adding value to data in health begins with the organized collection of a number of kinds of data , including data about patients in support of the resolution of clinical problems , data about processes of health administration , and data about financial transactions . 
For example , clinical data will consist of readings from remote sensors , meters , and other vital sign devices ; biometric data including fingerprints , genetics , handwriting , retinal scans , x‐ray and other medical images ; blood pressure , pulse , and pulse oximetry readings ; omics data ; along with the collection of further structured and unstructured clinical data about patients , for instance , electronic medical records , physicians ' notes , e‐mail , and paper documents ( Costa , 2014 ; IHTT , 2013 ; Raghupathi & Raghupathi , 2014 ) . 
Health administrative data will include human resource data that enables the monitoring and auditing of organizational performance ( Faulds et al. , 2016 ) —the latter incorporating data on treatments performed and targets met ; while financial data about transactions and healthcare claims will also be processed ( IHTT , 2013 ) . 
Besides the well‐documented risks arising from the collection , and subsequent processing , of personally identifying information , the main risks of organizing data from the health provider 's perspective relate to the opportunities of organizing big data . 
In other words , the loss of opportunity and risks to value of unified data‐driven health services not being developed due to the quality , variability , and veracity of the data collected ( Janke , Daniel , Overbeek , Kocher , & Levy , 2016 ; Kambatla , Kollias , Kumar , & Grama , 2014 ) . 
In addition , there will be resistance to the development of such unified data‐driven services ( Costa , 2014 ) from patients and others ( Janke et al. , 2016 ) , citing privacy and other concerns . 
In a business setting , the process of adding value to data for the delivery of automated services will incorporate the collection and organization of a range of different types of personally identifying information , including : account information , site or application interaction history , precise location‐based information ; along with other interactions both prior to and during interaction with the service , for example , third‐party referrals , and site navigation . 
Data about what information users share , with whom , via which channels ( for instance , instant messaging , social media , e‐mail ) will also be gathered . 
In this way , a profile of the actions and behaviors of an individual user can be stored and exploited for the subsequent delivery of targeted content and advertising . 
For the purposes of gaining further insight , data‐driven services will also seek to automate the collection and subsequent processing of information about their users ' actions and behaviors on other connected platforms . 
In this way the automated and implicit capture , pooling , analysis , and display of Personally Identifiable Information ( PII ) , can be supplemented by the gathering of explicit user‐generated content on social media channels . 
In contrast to the risks to value arising from the unified and organized collection and subsequent processing of big data , the risks of collecting and organizing data for automated data‐driven services will primarily relate to user concerns surrounding the extent , use , and onward processing of personally identifying information . 
In a health setting , the processes of adding value to data at the analyzing and judging phases of data work incorporate a number of information analyses based on the application of data analytics to the types of different data collected , for instance , clinical , administrative , and financial data . 
This includes the application of analytics to clinical audio data , which have been used to analyze a patient 's communication patterns or to make judgments about their emotional status ; along with the use of predictive analytics that can “ target identification of early readmissions risk , ” and “ facilitate population health management and value‐based accountable care , ” the latter of which has also emerged as a core strategy for detecting fraud in claims for health insurance ( Edelstein , 2013 , p. 16 ) . 
The application of analytics to administrative data can also support the preparation of reports on , and release of , data sets to external bodies concerned with health performance outcomes . 
The risks of information analyses in health relate to issues of : propensity arising from big data analyses that may prejudge the likelihood of a certain outcome , for instance , survival rates ; issues of data ownership , governance , and standards including data sharing with external organizations ; physicians ' views on the costs , risks , and liabilities of working with data ( Neff , 2013 ) ; issues of trust and ethics ( Childs & McLeod , 2015 ; McLeod & Childs , 2018 ) , plus patients ' expectations surrounding privacy in the face of demonstrable empirical evidence of continuing data breaches ( Kambatla et al. , 2014 ; Kayyali , Knott , & Van Kuiken , 2013 ) . 
In a business setting , the processes of adding value to data as part of information analyses in support of automated data‐driven services include the use of sentiment analysis , summarization , and other content‐analytical techniques for the analysis of textual data ; the analysis of audio data ( for instance , recorded and live calls to call centers ) via transcription , indexing , and searching of speech content ; and the analysis of video data via indexing and searching of video content ( Gandomi & Haider , 2015 ) . 
Text , audio , and video content‐related techniques can also be used in conjunction with further network structure‐based techniques for the purposes of extracting other participants and relations , identifying implicit communities , and modeling and analyzing social influence ; while predictive analytics aimed at anticipating future customer behaviors can also be applied to each of these same data types ( Gandomi & Haider , 2015 ) . 
The risks of information analyses in support of automated data‐driven services primarily relate to transparency , trust in big data analyses , and the manipulation of reputation . 
Indeed , these are concerns of all data mining technologies ( Pang & Lee , 2008 ) , as they are of the algorithmic processes of which data mining forms an element ( Dormehl , 2015 ) . 
In addition to the risks directly arising from the process of information analysis , the key risk remains the quality of the data upon which the analyses are based . 
Since big data analyses rely less on deductive‐driven statistical analysis and more on the inductive discovery of patterns and correlations , the heterogeneity of data , accumulation of noise , spurious correlations , incidental endogeneity , and other measurement errors also represent specific challenges to the use of big data analytical techniques . 
Such risks also represent a risk to the acceptance of big data analyses and a firm 's perceptions of the validity of such analyses ( Kwon , Lee , & Shin , 2014 ) . 
In a health setting , the resulting information analyses will both inform and provide productive knowledge in support of clinical decision making about personalized patient care , as well as administrative decision making relating to the effective yet economic delivery of health care . 
The latter will include the return of performance data to external authorities that can in turn be used to inform decision making in relation to managing a population 's health . 
In summary “ …big data analytics applications in health care take advantage of the explosion in data to extract insights for making better informed decisions ” ( Raghupathi & Raghupathi , 2014 , p. 1 ) . 
The risks of data‐driven decision making in health include concerns not only about the integrity and validity of ( big data ) analyses but also perceptual risks . 
Clinical professionals , for example , may require considerable persuasion as to the worth of investing in ( big ) data analytics and its relevance to clinical priorities , and how the benefits of this data work outweigh the costs , risks , and liabilities involved ( Neff , 2013 ) . 
In a business setting , the values of automated data‐driven decision making are several . 
First , user and use value‐oriented , in which descriptive data analytics provide users with the additional value of real‐time information in order to inform different kinds of decision making ; for instance , travel planning ( TomTom , FlightStats ) , financial decisions ( Xignite ) , or leisure bookings , ( OpenTable ) . 
These descriptive data analytics can be supplemented with the use of predictive analytics , and network structure‐based techniques , the latter of which is used to inform social media relations . 
Second , provider‐ and exchange value‐oriented . 
The analysis of closed circuit television footage in retail can lead to insights for example into customers ' queuing behavior and how customers move around a store : “ Valuable insights can be obtained by correlating this information with customer demographics to drive decisions for product placement , price , assortment optimization , promotion design , cross‐selling , layout optimization , and staffing ” ( Gandomi & Haider , 2015 , p. 141 ) . 
Finally , with the advent of data‐driven interactions , the value of automated data‐driven services also rests in their capacity to provide precisely tailored content and recommendations ; plus via the capture and analysis of further data prior to , during , and after the immediate service interaction , maintain a continuous relationship with their users . 
This set of processes , along with an illustration of their use in different problem‐oriented and data‐driven settings , provide an initial illustration of the value and risks of data work at the micro‐level . 
Table 1 provides a summary of the value and risks identified . 
The conduct of data work entails attention to negotiating a trade‐off between the value and risks that its processing presents . 
The addressing of this trade‐off requires locating data work within the context of its conditions and consequences . 
These conditions exist at a macro ( for instance , international , national , sectoral ) , meso ( for instance , organizational , institutional , consortium‐based ) , and micro level ( for instance , education and training of data professionals and others involved in systematic data‐handling ) . 
With regard to the macro conditions of data work , the literature comes from several research areas : law , information ethics , computer science , cultural policy , information policy , and mass communication . 
For the purposes of this review , we draw on this literature and focus on the structural conditions pertaining to two issues relevant to the value and risks of organizing and analyzing data at a micro‐level : the history , regulations , and policy surrounding data ownership ; and the structural conditions relating to the value and risks involved in the processing and re‐use of personally identifiable information . 
This latter is especially pertinent in an era when a contextual understanding of privacy is becoming both more key and prevalent for users and providers alike . 
Ownership actually involves at least four separate subissues : that of the service user , the content rights holder , the service/distribution owner , and the third‐party data‐driven innovation process owner . 
While the use of personal data has always been protected in its use for trade ( OECD , 1980 , 2011 ) , the re‐use of personal data and the advent of big data unavoidably increase the vulnerabilities between endpoints , and both legal and criminal exploitation must be considered . 
These issues overlap and entangle with each other and involve research reflecting on two separate policy streams : intellectual property rights ( IPR ) and data protection . 
Both issues have emerged from doctrines on personality rights ( Bygrave , 2002 ) . 
Notions of copyright have been influential in the grounding of privacy rights and vice versa . 
Historically , IPR has for several centuries played out as a competition between two different views ( Sell & May , 2001 ) . 
The first view is weak ownership for the content rights holder , maintaining that the public should be allowed free access to information , as this is a prerequisite for the development of culture , society , and democracy . 
As an extension , this ensures an educated labor force , increases in entrepreneurial activity , and economic growth . 
With the second view , strong ownership for the content rights holder , the argument is made that creators of original content should be well compensated . 
As an extension , this creates drivers for innovation , creativity , and entrepreneurship . 
The Global Agreement on Trade in Tariffs ( GATT ) , created in 1947 , had been a driver of international legislation on intellectual property rights since the 1970s . 
When GATT morphed into the World Trade Organization ( WTO , 1994 ) in 1995 , it was constituted with three main agreements that all members were obliged to follow ( Crews , 1998 ; May , 2003 ) . 
One of these was the Agreement on Trade Related Aspects of Intellectual Property Rights ( TRIPs ) . 
The TRIPs agreement signaled a global switch from a weak to a strong ownership viewpoint , and therefore constitutes a crucial foundation for data‐driven innovation . 
It is in this rather simplified polarity between producers and customers of culture , that behavioral tracking through sensors and Internet usage is introduced . 
The legal status of who owns the data generated by peoples ' online and offline every‐day practices has until today not been clarified . 
It is notable that the turn to a strong ownership viewpoint served as a disturbance in what was otherwise an emerging zeitgeist of weak ownership ; that is , privileging the user of the service . 
However , as practices of file sharing were seen to threaten industrial interests of culture and software , it was deemed necessary to develop legal frameworks that allowed for tracking of Internet behavior . 
Perhaps unintentionally , the TRIPs agreement created such a foundation for national legislation on digital IPR . 
The focus of the agreement was actually producers and sellers of pirated material goods . 
An additional problem with IPR legislation is that notions of ownership from an analog context have been applied to the digital marketplace without any concern about materiality and immateriality . 
IPR legislation has been called “ path dependent ” ( Litman , 2001 ) , as the legal framework concerning illegal copying of material goods also came to include digital goods . 
This created a legal framework within which ordinary users were seen as upholding the same criminal status as that of professional distributors of pirated brands simply by virtue of copying a musical track , a piece of software , or any other kind of digital product ( Larsson & Svensson , 2010 ) . 
